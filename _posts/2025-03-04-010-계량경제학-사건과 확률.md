---
title: 010-계량경제학 사건과 확률
date: 2025-03-04 12:00:00 +0900
categories: [계량경제학, Mathematical statistics]
tags: [econometric, probability, event, conditional probability, conditional expectation, almost sure convergence, convergence in probability, convergence in distribution, law of large numbers, central limit theorem, asymptotic distribution]
author: rachihyeon 
description: 여러 변형 OLS에 앞서 필요한 수리통계학 내용을 다룹니다. 또한 classical assumption에서 오차항의 정규성이 없을 때도 ols estimator가 정규성을 따르는지 확인해봅니다.
# comments: 
# media_subpath: 
# pin: true
math: true
mermaid: true
---

[계량경제학 포스트 보러가기](/categories/계량경제학/)

## 0. Introduces

우리는 [Gauss Markov Theorem](/posts/005-계량경제학-Gauss-Markov-Theorem/#2-1-classical-assumption)에서 몇 가지 가정을 했었다.

0. $$X_t$$는 **not random**, $$\epsilon_t$$는 **random**이다.

1. $$E[\epsilon_t]$$=0

2. $$Var[\epsilon_t]=\sigma^2$$, *homoskedasticity*

3. $$Cov(\epsilon_t, \epsilon_s)=0, for \ \  t \ne s$$, *no serial correlation*

4. $$\epsilon_t\sim N(0, \sigma^2)$$.

이런 형태였는데 이 조건은 생각보다 강한 조건이다. 구속력이 강력하다는 것이다.

사실 중요한 건 우리가 미래의 $$Y$$를 예측할 때 사용하는 $$X$$에 대해서 random이면 된다는 사실이니까, 위 조건을 느슨하지만 OLS estimator가 BLUE를 만족하도록 수정할 필요가 있는 것이다. 그렇게 변경한 조건이야말로 모델에 적합한 가정이라고 할 수 있는 것이다.

<br>
<br>
<br>

## 1. Conditional

이 섹션에서는 조건부에 어떤 종류가 있는지 알아보겠다.

<br>

### 1-1. Conditional Probability

조건부 확률이란 한 사건이 발생했을 때, 다른 사건이 발생할 확률을 의미한다. 여기서 중요한 것은 한 사건이 발생했다는 가정이다.

따라서 표기는 $$P(A\vert B)$$로 쓰며 이 의미는 $$B$$가 발생했을 때 $$A$$가 발생할 확률이다. 그리고 위 정의에 따라 이 값을 계산하는 방법은 다음과 같다.

$$P(A\vert B)=\frac{P(A\cap B)}{P(B)}$$

<br>

### 1-2. Conditional Expectation

조건부 기댓값이라는 것도 있다. 한 확률변수의 값이 고정됐을 때, 다른 확률변수의 기댓값이다. 조건부 확률의 표기법을 빌려 표현하면, $$E(Y\vert X)$$이다.<br>
계산식은 다음과 같다.

$$
E(Y)=\int_{}^{}y\cdot f_Y(y)dy \\
$$

$$
E(Y\vert X)=\int_{}^{}y\cdot f_{Y\vert X}(y\vert x)dy \\
$$

이때 $$f_{Y\vert X}(y\vert x)$$는 조건부 분포이며, 조건부 확률의 정의로부터 $$f_{Y\vert X}(y\vert x)=\frac{f(x,y)}{f_X(x)}$$이다.

이 조건부 기댓값에 대한 여러 정리들이 있다.

\\
$$
\begin{align}
&E(X\vert X)=X \\
\\
&E(XY\vert X)=X\cdot E(Y\vert X) \\
\\
&E(Y+Z\vert X)=E(Y\vert X)+E(Z\vert X) \\
\\
&X \mathrm{와} Y\mathrm{가 독립이라면, } E(Y\vert X)=E(Y) \\
\\
&E(Y\vert X)=E(Y)\mathrm{이면, }Cov(X, Y)=0 \\
\\
&E(E(Y\vert X))=E(Y) \quad \mathrm{(the\ law\ of\ iterated\ expectation)}
\end{align}
$$

~~증명은 쓰기 귀찮다... 별로 어렵지 않으니 혼자 해보는 것을 추천한다.~~

<br>

### 1-3. Classical Assumption

$$Y_t=X_t'\beta^*+\epsilon_t$$라는 모델에 대한 가정을 새로 작성하면 아래와 같다.

1. $$E[\epsilon \vert X]$$=0

2. $$Var[\epsilon \vert X]=\sigma^2$$, *homoskedasticity*

3. $$Cov(\epsilon_t, \epsilon_s \vert X)=0, for \ \  t \ne s$$, *no serial correlation*

4. $$\epsilon \vert X\sim N(0, \sigma^2)$$.

<br>
<br>

## 2. Convergence of Random variable

이번 섹션에서는 확률변수의 수렴에 대해 다룬다.

>확률 공간은 $$(\Omega, \mathcal{F}, P)$$로 정의된 사실을 기억하자.
{: .prompt-tip}

<br>

### 2-1. Sure Convergence(확실한 수렴)

확률 공간의 확률 변수 $$X_1, X_2, \dots$$와 $$X$$에 대하여<br>
$$\underset{n \to \infty}{\lim}X_n(\omega)=X(\omega)$$이면 $$\{X_n \}$$은 $$X$$로 확실하게 수렴한다고 한다. 
즉, 확률변수의 **모든 점**에 대해서 **각각 한 점으로 수렴**한다는 것이다.

<br>

### 2-2. Almost Sure Convergence(거의 확실한 수렴)

위의 확실한 수렴보다 약한 개념이며 모든 점이 아닌 거의 대부분의 점에 대해서 수렴하는 경우를 말한다.<br>
확률 공간의 확률 변수 $$X_1, X_2, \dots$$와 $$X$$에 대하여<br>
$$\mathrm{Pr}(\underset{n \to \infty}{\lim}X_n=X)=1$$이면 $$\{X_n \}$$은 $$X$$로 거의 확실하게 수렴한다고 한다. <br>
$$\mathrm{Pr}(\omega \in \Omega : \underset{n \to \infty}{\lim}X_n(\omega)=X(\omega))=1$$과 동치인 명제이다.

$$X_n \overset{a.s.}{\to} X$$라고 표기한다.

<br>

### 2-3. Convergence in Probability(확률 수렴)

위의 거의 확실한 수렴보다 더 약한 개념이며 점에 대한 수렴을 말하지 않고 전체적인 수렴을 말한다.<br>
확률 공간의 확률 변수 $$X_1, X_2, \dots$$와 $$X$$에 대하여<br>
$$\forall \epsilon \gt 0, \underset{n \to \infty}{\lim} \mathrm{Pr}(\vert X_n-X\vert \ge \epsilon)=0$$이면 $$\{X_n \}$$은 $$X$$로 확률 수렴한다고 한다. <br>

$$X_n \overset{p}{\to} X$$혹은 $$\underset{n \to \infty}{\operatorname{plim}}X_n=X$$라고 표기한다.

언뜻 보면 거의 확실한 수렴과 확률 수렴이 구별이 어려울 수 있다. 하지만 정의를 자세히 보자. 거의 확실한 수렴의 경우 거의 모든 점에서 $$X$$와 같아져야 한다. 하지만 확률수렴의 경우 아얘 모든 점에서 달라도 된다. <br>
즉, $$\mathrm{Pr}(\underset{n \to \infty}{\lim}X_n=X)=0.000001$$이어도 확률 수렴이 가능할 수 있다는 것이다.

>필자는 이 사실을 받아들이는데 한 가지 예시를 만들어서 이해했다.<br>
>예를 들어, 일련의 시험들에서 학생들의 평균 점수가 특정 값(ex, 80)에 가까워지면, 확률적으로 수렴한다고 말 할 수 있다. 하지만 개별 학생의 점수가 그 값으로 수렴함을 보장하지는 않는다. 따라서 이 경우는 확률수렴이다.<br>
>만약, 학생의 수가 충분히 많아져 결국 대부분의 학생으 평균 점수가 특정 값에 가까워지는 상황이라면, 이는 거의 확실한 수렴이라고 볼 수 있다.
{: .prompt-tip}

>따라서 거의 확실한 수렴이면 확률 수렴이다. (이산 확률 공간에서는 동치이다.)
{: .prompt-info}

<br>

### 2-4. Convergence in Distribution(분포 수렴)

분포 수렴이란, 확률 변수의 누적 분포 함수(CDF)가 수렴하는 것을 의미한다. <br>
확률 공간의 확률 변수 $$X_1, X_2, \dots$$와 $$X$$, 각각의 확률 변수에 대한 누적 분포 함수 $$F_1, F_2, \dots$$, $$F$$에에 대하여<br>
$$\underset{n \to \infty}{\lim}F_n(x)=F(x)$$이면 $$\{X_n \}$$은 $$X$$로 분포 수렴한다고 한다. <br>

이 말은 $$\{X_n \}$$의 형태가 어찌 됐든 간에 결국 $$F$$의 형태로 분포가 나타난다는 뜻이다. <br>
따라서 $$X_n \overset{d}{\to} X$$혹은 $$X_n \overset{A}{\to} \mathcal{L}_X$$라고 표기한다.(이때 $$\mathcal{L}$$은 확률 분포를 가리킨다.)

>확률 수렴이면 분포 수렴이다. (분포가 상수로 수렴하면 분포 수렴과 확률 수렴은 동치이다.)
{: .prompt-info}

<br>

### 2-5. Theorem and Lemma

확률 변수의 수렴에 관련된 여러 정리들이 있다.

1. $$X_n \overset{p}{\to} X, Y_n \overset{p}{\to} Y$$이면, 아래가 만족된다.<br>
$$
\begin{align}
&X_n+Y_n \overset{p}{\to} X+Y \\
&X_nY_n \overset{p}{\to} XY \\
&\frac{X_n}{Y_n} \overset{p}{\to} \frac{X}{Y} (Y \ne 0) \\
\end{align}
$$

2. $$X_n-Y_n \overset{p}{\to} 0, X_n \overset{d}{\to} X$$이면, $$Y_n \overset{d}{\to} Y$$

3. $$X_n \overset{d}{\to} X, Y_n \overset{p}{\to} Y$$이면, $$X_nY_n \overset{p}{\to} 0$$

4. $$X_n \overset{d}{\to} X, Y_n \overset{p}{\to} c$$이면, 아래가 만족된다.<br>
$$
\begin{align}
&X_n+Y_n \overset{p}{\to} X+c \\
&X_nY_n \overset{p}{\to} Xc \\
&\frac{X_n}{Y_n} \overset{p}{\to} \frac{X}{c} (c \ne 0) \\
\end{align}
$$

<br>

### 2-6. Law of Large Numbers(큰 수의 법칙)

동일한 확률 분포를 가지며 서로 독립적인(이하 i.i.d.) 확률 변수 $$\{X_n \}$$에 대해서 적당한 유한 값 $$\mu^* < \infty$$가 존재하여,

$$\hat{\mu}_T=\frac{1}{T} \sum _{n=1}^{T}X_n \overset{a.s.}{\to}\mu^*=E(X_n)$$

가 만족한다. 우리가 고등학생 때 배웠던 표본평균의 기댓값이 모평균에 거의 확실하게 수렴한다는게 이 말이다.(~~그때는 야얘 같다고 놨었지만...~~)

<br>

### 2-7. Central Limit Theorem(중심 극한 정리)

i.i.d. 확률 변수 $$\{X_n \}$$에 대해서 적당한 유한 기댓값과 분산 $$\mu^*, \sigma^2 < \infty$$가 존재하여,

$$\frac{\sqrt{T}(\bar{X_n}-\mu^*)}{\sigma} \overset{d}{\to} N(0, 1)$$

가 만족한다. 우리가 고등학생 때 사용했던 표본평균의 분포가 정규분포를 따른다는 사실이 여기서 나온 것이다. 

<br>
<br>

## 3. OLS estimator의 분포 근사

[위에서 조건부 기댓값을 적용한 가정들](/posts/010-계량경제학-사건과-확률/#1-3-classical-assumption)을 새로 했는데, 이 가정 하에서 OLS estimator의 속성에 대해서 확인을 해보겠다.

$$
\begin{align}
\hat{\beta}&=(X'X)^{-1}X'Y=(X'X)^{-1}X'(X'\beta^*+\epsilon) \\
&=\beta^*+(X'X)^{-1}X'\epsilon \\
\end{align}
$$

이니

$$
\begin{align}
E(\hat{\beta})&=E(E(\hat{\beta} \vert X)) \\
&=E(\beta^*+E((X'X)^{-1}X'\epsilon \vert X)) \\
&=E(\beta^*+(X'X)^{-1}X'E(\epsilon \vert X)) \\
&=E(\beta^*) \\
&=\beta^*
\end{align}
$$

따라서 Unbiasedness이다.

<br>

### 3-1. 근사를 위한 가정들

1. $$\{ (X_t, \epsilon_t) \}$$는 i.i.d. <br>
2. $$E(\epsilon_t)=0, Var(\epsilon_t)=\sigma_0^2<\infty$$ <br>
3. $$Q\equiv E(X_tX_t'),\quad Q\  \mathrm{is\ nonsingular\ matrix}$$ <br>
4. $$E(X_t\epsilon_t)=0$$ <br>
5. $$E(\epsilon_t^2 \vert X_t)=\sigma_0^2$$ <br>

<br>

### 3-2. 분포 근사

\\
$$
\begin{align}
\hat{\beta}&=(X'X)^{-1}X'Y \\
&=(\sum _{t=1}^{T} X_tX_t')^{-1}\sum _{t=1}^{T} X_tY_t=\beta^* + (\frac{1}{T} \sum _{t=1}^{T} X_tX_t')^{-1}\frac{1}{T}\sum _{t=1}^{T} X_t\epsilon_t \\
\end{align}
$$

<br>
[큰 수의 법칙](/posts/010-계량경제학-사건과-확률/#2-6-law-of-large-numbers큰-수의-법칙)에 의해,
\\
$$
\begin{align}
\frac{1}{T} \sum _{t=1}^{T} X_tX_t' \overset{p}{\to} E(X_tX_t'), \frac{1}{T} \sum _{t=1}^{T} X_t\epsilon_t \overset{p}{\to} E(X_t\epsilon_t)
\end{align}
$$

이니
\\
$$
\begin{align}
(\frac{1}{T} \sum _{t=1}^{T} X_tX_t')^{-1}\frac{1}{T}\sum _{t=1}^{T} X_t\epsilon_t \overset{p}{\to} Q^{-1}E(X_t\epsilon_t)=0
\end{align}
$$

이다. 따라서 $$\hat{\beta} \overset{p}{\to}\beta^*$$ consistent estimator이다.

위 식들로부터,

$$
\sqrt{T}(\hat{\beta}-\beta^*)=(\frac{1}{T} \sum _{t=1}^{T} X_tX_t')^{-1}\frac{1}{\sqrt{T}}\sum _{t=1}^{T} X_t\epsilon_t \\
$$

$$
Var(X_t\epsilon_t)=E[(X_t\epsilon_t-0)(X_t\epsilon_t-0)']=E[\epsilon_t^2X_tX_t']=E[E[\epsilon_t^2X_tX_t'\vert X_t]]=E[E[\epsilon_t^2X_t]X_tX_t']=\sigma^2Q \\
$$

인데, [위 가정들](/posts/010-계량경제학-사건과-확률/#3-1-근사를-위한-가정들)을 기반으로 [중심극한정리](/posts/010-계량경제학-사건과-확률/#2-7-central-limit-theorem중심-극한-정리)를 이용하면,

$$
\frac{1}{\sqrt{T}}\sum _{t=1}^{T} X_t\epsilon_t \overset{d}{\to} N(0, \sigma^2Q)
$$

근데 모분산은 알려져있지 않은 경우가 많다. 따라서 모표준편차를 대체할 값이 필요한데, [검정에 대해 다룬 포스트](/posts/006-계량경제학-Test/#3-1-불편량)에서 사용했던 방법을 사용하겠다.

$$\hat{\sigma ^2}=\frac{1}{T-k}\sum _{\ }^{\ }e _t^2 \overset{p}{\to} \sigma^2$$

최종적으로,

$$
\begin{align}
&\sqrt{T}(\hat{\beta}-\beta^*)=(\frac{1}{T} \sum _{t=1}^{T} X_tX_t')^{-1}\frac{1}{\sqrt{T}}\sum _{t=1}^{T} X_t\epsilon_t \overset{d}{\to} Q^{-1}N(0, \sigma^2Q) \\
&\Rightarrow (\hat{\beta}-\beta^*) \overset{d}{\to} N(0, \frac{1}{T}\sigma^2Q^{-1}) \\
&\Rightarrow \hat{\beta} \overset{d}{\to} N(\beta^*, \hat{\sigma}^2(X'X)^{-1}) \\
\end{align}
$$

<br>
<br>

후기) 이번에는 ols에 필요한 가정 중 오차항의 정규성이 굳이 필요하지 않아도 샘플의 수가 크면 추정량이 정규분포를 따른다는 사실을 알아봤습니다... 이런 기법들을 자줄 쓸테니 알아 두시면 도움이 될 겁니다.

***오타 혹은 잘못된 정보가 있다면 댓글 이메일 등등으로 알려주시면 감사하겠습니다. (꾸벅)***