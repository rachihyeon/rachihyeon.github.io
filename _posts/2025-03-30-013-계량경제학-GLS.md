---
title: 013-계량경제학 GLS(Generalized least squares)
date: 2025-03-30 21:00:00 +0900
categories: [계량경제학, GLS]
tags: [econometric, gls, cochrane-orcutt method]
author: rachihyeon 
description: OLS estimator를 사용하면 분산에 대한 여러 검정을 할 필요가 있다. 그렇다면 분산에 대한 검정을 하지 않아도 되는 추정량인 GLS estimator에 대해서 다룹니다.
# comments: 
# media_subpath: 
# pin: true
math: true
mermaid: true
---

><span style="font-size: 20px;">**!!필독!!** <br>
>수식편집기의 버그로 수식 번호가 모두 매겨져 있는 경우가 있습니다. <br>
>이 경우 **새로고침(F5)**하여 없앤 후 읽어주시길 바랍니다.</span>
{: .prompt-danger}

<br>

[계량경제학 포스트 보러가기](/categories/계량경제학/)

## 0. Introduction

우리가 OLS estimator를 사용할 때 필요한 분산에 대한 조건들이 있었다. 하지만 이 조건들은 검정이 반드시 필요하기 때문에 여러 계산이 필요하기도 하고 만족시키기 참 어렵다.<br>
그래서 이번 포스트에서는 분산에 대한 조건인 등분산성이나 자기상관성이 깨지는 데이터라도 BLUE가 되는 추정량인 GLS추정량을 알아보겠습니다.

<br>
<br>
<br>

## 1. GLS estimator

등분산성 보장되지 않은 DGP에서의 오차항의 분산 $$Var(\epsilon)=E(\epsilon \epsilon')=\Omega \ne \sigma^2I$$이다.<br>
따라서 우리는 OLS가 아니라 GLS추정량을 사용해야한다. <br>
일반적인 DGP에서의 OLS estimator $$\hat{\beta}$$은 불변성, 일치성은 만족하지만 Best는 아니다. (그 이유가 궁금하다면 [여기](/posts/011-계량경제학-Heteroskedasticity/#1-등분산성-조건-제거)를 참고하길 바랍니다.)

자 이제 진짜 GLS estimator를 구하기 위해서 새로운 DGP를 아래와 같이 만들어보자.

DGP : $$Y=X\beta+\epsilon$$ <br>
New DGP : $$\Omega^{-1/2}Y=\Omega^{-1/2}X\beta+\Omega^{-1/2}\epsilon \Rightarrow \tilde{Y}=\tilde{X}\beta+\tilde{\epsilon}$$

위와 같은 새로운 DGP를 만들면 여기서의 오차항인 $$\tilde{\epsilon}$$는 $$Var(\tilde{\epsilon})=\Omega^{-1/2}\Omega \Omega^{-1/2}=I$$이니, 등분산성도 만족하고 자기상관성 없음 조건도 만족한다. 따라서 **깨끗한 오차항**이라고 할 수 있다. <br>
그 말인즉슨, Gauss-Markov Theorem을 적용할 수 있다는 것이다.

>일반적으로 오차항의 분산행렬은 positive semi-definite인데 보통 행렬식 값이 완전히 0이 되는 경우는 없어서 정칙이다. 그리고 A가 대칭행렬이면 A의 역행렬도 대칭행렬이니 직교 대각화 가능하다. 따라서 $$\Omega$$는 역의 제곱근 행렬($$\Omega^{-1/2}$$)이 존재한다.
{: .prompt-tip}

Gauss-Markov Theorem를 적용한 GLS추정량은 아래와 같다.

$$
\begin{align}
\tilde{\beta}&=(\tilde{X}'\tilde{X})^{-1}\tilde{X}'\tilde{Y}=(X'(\Omega^{-1/2})'(\Omega^{-1/2})X)^{-1}X'(\Omega^{-1/2})'(\Omega^{-1/2})Y \\
&=(X'\Omega^{-1}X)^{-1}X'\Omega^{-1}Y \\
\end{align}
$$

GLS estimator를 구해봤으니 OLS estimator와 비교해보자. (둘 다 불변량임을 보이는 것은 쉬우니 생략하겠다.)

GLS estimator의 variance<br>
$$
\begin{align}
Var(\tilde{\beta})&=Var((\tilde{X}'\tilde{X})^{-1}\tilde{X}'\tilde{Y}) \\
&=Var((X'(\Omega^{-1/2})'(\Omega^{-1/2})X)^{-1}X'(\Omega^{-1/2})'(\Omega^{-1/2})\epsilon) \\
&=(X'\Omega^{-1}X)^{-1}X'\Omega^{-1}Var(\epsilon)\Omega^{-1}X(X'\Omega^{-1}X)^{-1}  \\
&=(X'\Omega^{-1}X)^{-1}X'\Omega^{-1}\Omega \Omega^{-1}X(X'\Omega^{-1}X)^{-1} \\
\Rightarrow Var(\tilde{\beta}) &=(X'\Omega^{-1}X)^{-1}
\end{align}
$$

OLS estimator의 variance<br>
$$
\begin{align}
Var(\hat{\beta})&=Var((X'X)^{-1}X'Y)=Var((X'X)^{-1}X'\epsilon) \\
&=(X'X)^{-1}X'Var(\epsilon)X(X'X)^{-1} \\
&=(X'X)^{-1}X'\Omega X(X'X)^{-1} \\
\Rightarrow Var(\hat{\beta}) &=(X'X)^{-1}X'\Omega X(X'X)^{-1}
\end{align}
$$

두 행렬 A, B에 대해서 A-B가 positive definte이면 $$\frac{1}{B}-\frac{1}{A}$$도 positive definite이다.

우리가 확인해야 하는 것은 $$Var(\hat{\beta})-Var(\tilde{\beta})$$가 positive definite이라는 것이니까,

$$\frac{1}{Var(\tilde{\beta})}-\frac{1}{Var(\hat{\beta})}$$를 확인해보자.

$$
\begin{align}
(Var(\tilde{\beta}))^{-1}-(Var(\hat{\beta}))^{-1}&=(X'\Omega^{-1}X)-(X'X)(X'\Omega X)^{-1}(X'X) \\
&=(X'\Omega \Omega^{-1}\Omega X)-(X'X)(X'\Omega X)^{-1}(X'\Omega X)(X'\Omega X)^{-1}(X'X) \\
\\
\mathrm{Let}\ V=X'&\Omega^{-1}-(X'X)(X'\Omega X)^{-1}X' \\
(Var(\tilde{\beta}))^{-1}-(Var(\hat{\beta}))^{-1}&=V\Omega V'
\end{align}
$$

그리고 이건 positive semi-definite이다. 따라서 GLS estimator는 OLS estimator보다 efficient하다.

<br>
<br>

## 2. Cochrane-Orcutt Method

근데 <span style = "color : red;">가장 큰 문제 하나</span>가 있다. 바로 $$\Omega$$를 알 수 없다는 것이다.<br>
그래서 추정해야한다. 근데 또 문제가 있다.

$$\Omega$$는 $$T\times T$$행렬인데 대칭행렬이라고 해도 모르는 수가 $$\frac{T(T+1)}{2}$$개 이다. 그렇다보니 우리가 $$\Omega$$를 전부 추정해내는 것은 불가능에 가깝다. 따라서 몇 가지 제약사항을 걸어놓고 추정한다.

두 가지 방법이 있는데,<br>
$$1$$. 자기상관성이 없고, 분산은 두 가지만 존재한다.<br>
즉, 
$$
\Omega = 
\begin{bmatrix}
\sigma_1 ^2 & \cdots       &            &               &              &              \\
\vdots      & \ddots       &            &               &              &              \\
            &              & \sigma_1^2 &               &              &              \\
            &              &            & \sigma_2 ^2   &              &              \\
            &              &            &               & \ddots       & \vdots       \\
            &              &            &               & \cdots       & \sigma_2 ^2  \\
\end{bmatrix}
$$

여기서 $$\hat{\sigma_1}^2=\frac{1}{T_1-k} \sum _{t=1} ^{T_1} e_t^2,\ \ \hat{\sigma_2}^2=\frac{1}{T-T_1-k} \sum _{t=T_1+1} ^{T} e_t^2$$이다.

$$2$$. 이분산성이 없고, 자기상관성이 있다.<br>
즉,
$$
\Omega = 
\begin{bmatrix}
1           & \rho^*       & \cdots     & \rho^{*T-1}  \\
\rho^*      & 1            &            & \rho^{*T-2}  \\
\vdots      &              & \ddots     & \vdots       \\
\rho^{*T-1} & \rho^{*T-2}  & \cdots     & 1            \\
\end{bmatrix}
\ne \sigma^2 I_T
$$

2번 방법이라면, 오차항이 $$\epsilon_t=\rho^*\epsilon_{t-1}+\eta_t$$처럼 표현되니까까,<br>
DGP : $$Y=X\beta+\epsilon$$ <br>
New DGP : $$Y-\rho LY=(X-\rho LX)\beta+\epsilon-\rho L\epsilon \Rightarrow \tilde{Y}=\tilde{X}\beta+\tilde{\epsilon}$$<br>
로 설계되고, 여기서 $$\tilde{\epsilon}$$는 깨끗한 오차항이니 Gauss-Markov 정리를 적용할 수 있다.

<br>
<br>

후기) 오차항의 분산에 관련하여 여러 검정을 할 때 아싸리 GLS먼저 써보고 괜찮은지 확인해보는 것도 좋은 방법이다.

***오타 혹은 잘못된 정보가 있다면 댓글 이메일 등등으로 알려주시면 감사하겠습니다. (꾸벅)***